{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR set to 0.005\n",
      "LR set to 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvipl/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/cvipl/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/cvipl/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-affc2363de1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     print('[%d/%d] Loss_D: %.4f Loss_G %.4f D(x): %.4f D(G(z)): %.4f / %.4f' \\\n\u001b[0;32m--> 297\u001b[0;31m         % (epoch, epochs, errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mplot_every_epochs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import datetime\n",
    "#%matplotlib\n",
    "\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "def update_learning_rate(optimizer, epoch, init_lr, decay_rate, lr_decay_epochs):\n",
    "    lr = init_lr * (decay_rate**(epoch // lr_decay_epochs))\n",
    "    \n",
    "    if epoch % lr_decay_epochs == 0:\n",
    "        print('LR set to {}'.format(lr))\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def samples(\n",
    "    models,\n",
    "    data,\n",
    "    sample_range,\n",
    "    batch_size,\n",
    "    num_points=10000,\n",
    "    num_bins=100\n",
    "):\n",
    "    '''\n",
    "    Return a tuple (db, pd, pg), where db is the current decision\n",
    "    boundary, pd is a histogram of samples from the data distribution,\n",
    "    and pg is a histogram of generated samples.\n",
    "    \n",
    "    Taken from https://github.com/AYLIEN/gan-intro/blob/master/gan.py\n",
    "    '''\n",
    "    xs = np.linspace(-sample_range, sample_range, num_points)\n",
    "    bins = np.linspace(-sample_range, sample_range, num_bins)\n",
    "\n",
    "    # decision boundary\n",
    "    db = np.zeros((num_points, 1))\n",
    "    for i in range(num_points // batch_size):\n",
    "        sample = torch.FloatTensor(np.reshape(xs[batch_size * i : batch_size * (i + 1)], (batch_size, 1)))\n",
    "        sample = Variable(sample).cuda()\n",
    "        db[batch_size * i:batch_size * (i + 1)] = models[0](sample).cpu().data.numpy()\n",
    "\n",
    "    # data distribution\n",
    "    d = data.sample(num_points)\n",
    "    pd, _ = np.histogram(d, bins=bins, density=True)\n",
    "\n",
    "    # generated samples\n",
    "    zs = np.linspace(-sample_range, sample_range, num_points)\n",
    "    g = np.zeros((num_points, 1))\n",
    "    for i in range(num_points // batch_size):\n",
    "        sample = torch.FloatTensor(np.reshape(zs[batch_size * i:batch_size * (i + 1)], (batch_size, 1)))\n",
    "        sample = Variable(sample).cuda()\n",
    "        g[batch_size * i:batch_size * (i + 1)] = models[1](sample).cpu().data.numpy()\n",
    "\n",
    "    pg, _ = np.histogram(g, bins=bins, density=True)\n",
    "\n",
    "    return db, pd, pg\n",
    "\n",
    "\n",
    "def plot_distributions(samps, sample_range, ax, save_img_name):\n",
    "    ax.clear()\n",
    "    db, pd, pg = samps\n",
    "    db_x = np.linspace(-sample_range, sample_range, len(db))\n",
    "    p_x = np.linspace(-sample_range, sample_range, len(pd))\n",
    "    #f, ax = plt.subplots(1)\n",
    "    ax.plot(db_x, db, label='decision boundary')\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.plot(p_x, pd, label='real data')\n",
    "    plt.plot(p_x, pg, label='generated data')\n",
    "    plt.title('1D Generative Adversarial Network')\n",
    "    plt.xlabel('Data values')\n",
    "    plt.ylabel('Probability density')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_img_name)\n",
    "    #plt.show()\n",
    "    #plt.pause(0.05)\n",
    "\n",
    "\n",
    "class DataDistribution(object):\n",
    "    def __init__(self):\n",
    "        self.mu = 4\n",
    "        self.sigma = 0.5\n",
    "\n",
    "    def sample(self, N):\n",
    "        samples = np.random.normal(self.mu, self.sigma, N)\n",
    "        samples.sort()\n",
    "        return np.reshape(samples, (-1, 1))\n",
    "\n",
    "\n",
    "class GeneratorDistribution(object):\n",
    "    def __init__(self, range):\n",
    "        self.range = range\n",
    "\n",
    "    def sample(self, N):\n",
    "        samples = np.linspace(-self.range, self.range, N) + \\\n",
    "            np.random.random(N) * 0.01\n",
    "        return samples\n",
    "\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H * 2)\n",
    "        self.linear2 = torch.nn.Linear(H * 2, H * 2)\n",
    "        self.linear3 = torch.nn.Linear(H * 2, H * 2)\n",
    "        self.linear4 = torch.nn.Linear(H * 2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = F.tanh(self.linear1(x))\n",
    "        h1 = F.tanh(self.linear2(h0))\n",
    "        h2 = F.tanh(self.linear3(h1))\n",
    "        out = F.sigmoid(self.linear4(h2))\n",
    "        return out\n",
    "\n",
    "def save_animation(anim_frames, anim_path, sample_range):\n",
    "    f, ax = plt.subplots(figsize=(6, 4))\n",
    "    f.suptitle('1D Generative Adversarial Network', fontsize=15)\n",
    "    plt.xlabel('Data values')\n",
    "    plt.ylabel('Probability density')\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(0, 1.4)\n",
    "    line_db, = ax.plot([], [], label='decision boundary')\n",
    "    line_pd, = ax.plot([], [], label='real data')\n",
    "    line_pg, = ax.plot([], [], label='generated data')\n",
    "    frame_number = ax.text(\n",
    "        0.02,\n",
    "        0.95,\n",
    "        '',\n",
    "        horizontalalignment='left',\n",
    "        verticalalignment='top',\n",
    "        transform=ax.transAxes\n",
    "    )\n",
    "    ax.legend()\n",
    "\n",
    "    db, pd, _ = anim_frames[0]\n",
    "    db_x = np.linspace(-sample_range, sample_range, len(db))\n",
    "    p_x = np.linspace(-sample_range, sample_range, len(pd))\n",
    "\n",
    "    def init():\n",
    "        line_db.set_data([], [])\n",
    "        line_pd.set_data([], [])\n",
    "        line_pg.set_data([], [])\n",
    "        frame_number.set_text('')\n",
    "        return (line_db, line_pd, line_pg, frame_number)\n",
    "\n",
    "    def animate(i):\n",
    "        frame_number.set_text(\n",
    "            'Frame: {}/{}'.format(i, len(anim_frames))\n",
    "        )\n",
    "        db, pd, pg = anim_frames[i]\n",
    "        line_db.set_data(db_x, db)\n",
    "        line_pd.set_data(p_x, pd)\n",
    "        line_pg.set_data(p_x, pg)\n",
    "        return (line_db, line_pd, line_pg, frame_number)\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        f,\n",
    "        animate,\n",
    "        init_func=init,\n",
    "        frames=len(anim_frames),\n",
    "        blit=True\n",
    "    )\n",
    "    anim.save(anim_path, fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N = 8  # batch size\n",
    "D_in = 1  # input size of D\n",
    "H = 4  # numbr of  hidden neurons\n",
    "D_out = 1\n",
    "learning_rate = 0.005\n",
    "epochs = 10000\n",
    "plot_every_epochs = 1000\n",
    "current_time = datetime.datetime.now().strftime(\"20%y%m%d_%H%M_%S\")\n",
    "output_path = '/tmp/{}'.format(current_time)\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "anim_path = output_path\n",
    "\n",
    "\n",
    "anim_frames = []\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "data_dist = DataDistribution()\n",
    "gen_dist = GeneratorDistribution(range=8)\n",
    "\n",
    "x = torch.FloatTensor(N, 1)\n",
    "z = torch.FloatTensor(N, 1)\n",
    "label = torch.FloatTensor(N)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "netD = Discriminator(D_in=D_in, H=H, D_out=D_out)\n",
    "netG = Generator(D_in=D_in, H=H, D_out=D_out)\n",
    "netD.apply(weights_init)\n",
    "netG.apply(weights_init)\n",
    "        \n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "if use_cuda:\n",
    "    x, z, label = x.cuda(), z.cuda(), label.cuda()\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "optimizerD = torch.optim.SGD(netD.parameters(), lr=learning_rate)\n",
    "optimizerG = torch.optim.SGD(netG.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create figure\n",
    "f, ax = plt.subplots(1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ############################\n",
    "    # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "    ###########################\n",
    "    # train with real: maximize log(D(x))\n",
    "    netD.zero_grad()\n",
    "    real_cpu = torch.FloatTensor(data_dist.sample(N))\n",
    "    if use_cuda:\n",
    "        real_cpu = real_cpu.cuda()\n",
    "    x.copy_(real_cpu)\n",
    "    label.fill_(real_label)\n",
    "    xv = Variable(x)\n",
    "    labelv = Variable(label)\n",
    "    \n",
    "    output = netD(xv)  # D(x)\n",
    "    errD_real = criterion(output, labelv)\n",
    "    errD_real.backward()\n",
    "    D_x = output.data.mean()\n",
    "    \n",
    "    # train with fake: maximize log(1 - D(G(z)))\n",
    "    z = torch.FloatTensor(gen_dist.sample(N))[...,None]  # (N_sample, N_channel)\n",
    "    if use_cuda:\n",
    "        z = z.cuda()\n",
    "    zv = Variable(z)\n",
    "    fake = netG(zv)   # G(z)\n",
    "    labelv = Variable(label.fill_(fake_label))\n",
    "    output = netD(fake.detach())   # D(G(z))\n",
    "    errD_fake = criterion(output, labelv)\n",
    "    errD_fake.backward()\n",
    "    D_G_z1 = output.data.mean()\n",
    "    errD = errD_real + errD_fake\n",
    "    optimizerD.step()\n",
    "    optimizerD = update_learning_rate(optimizer=optimizerD,\n",
    "                                      epoch=epoch,\n",
    "                                      init_lr=learning_rate,\n",
    "                                      decay_rate=0.95,\n",
    "                                      lr_decay_epochs=150)\n",
    "\n",
    "    ############################\n",
    "    # (2) Update G network: maximize log(D(G(z))): guide D make wrong prediction: G(z) --> real_label(1)\n",
    "    ###########################\n",
    "    netG.zero_grad()\n",
    "    labelv = Variable(label.fill_(real_label))\n",
    "    output = netD(fake)  # D(G(z))\n",
    "    errG = criterion(output, labelv)\n",
    "    errG.backward()\n",
    "    D_G_z2 = output.data.mean()\n",
    "    optimizerG.step()\n",
    "    optimizerG = update_learning_rate(optimizer=optimizerG,\n",
    "                                      epoch=epoch,\n",
    "                                      init_lr=learning_rate,\n",
    "                                      decay_rate=0.95,\n",
    "                                      lr_decay_epochs=150)\n",
    "    \n",
    "    #print('[%d/%d] Loss_D: %.4f Loss_G %.4f D(x): %.4f D(G(z)): %.4f / %.4f' \\\n",
    "    #    % (epoch, epochs, errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "    if epoch % plot_every_epochs == 0:\n",
    "        # Plot distribution\n",
    "        samps = samples([netD, netG], data_dist, gen_dist.range, N)\n",
    "        anim_frames.append(samps)\n",
    "        plot_distributions(samps, gen_dist.range, ax, save_img_name = output_path+'/{:06}'.format(epoch))\n",
    "\n",
    "# save_animation(anim_frames, anim_path, gen_dist.range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
